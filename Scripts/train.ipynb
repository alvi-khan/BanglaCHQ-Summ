{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model options: facebook/mbart-large-50, google/mt5-base, csebuetnlp/banglat5\n",
    "MODEL = \"facebook/mbart-large-50\"\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_OUTPUT_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "WEIGHT_DECAY = 3e-2\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 50\n",
    "NO_REPEAT_NGRAM_SIZE = 2\n",
    "NUM_BEAMS = 15\n",
    "LENGTH_PENALTY = 1\n",
    "USE_WANDB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-08T20:15:49.249528Z",
     "iopub.status.busy": "2023-06-08T20:15:49.249077Z",
     "iopub.status.idle": "2023-06-08T20:16:00.511487Z",
     "shell.execute_reply": "2023-06-08T20:16:00.509960Z",
     "shell.execute_reply.started": "2023-06-08T20:15:49.249490Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from statistics import mean\n",
    "from rouge import Rouge\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T20:16:03.257353Z",
     "iopub.status.busy": "2023-06-08T20:16:03.256327Z",
     "iopub.status.idle": "2023-06-08T20:16:03.432797Z",
     "shell.execute_reply": "2023-06-08T20:16:03.431616Z",
     "shell.execute_reply.started": "2023-06-08T20:16:03.257307Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../Dataset\"\n",
    "train = pd.read_csv(f\"{path}/train.csv\")\n",
    "valid = pd.read_csv(f\"{path}/valid.csv\")\n",
    "test = pd.read_csv(f\"{path}/test.csv\")\n",
    "\n",
    "train = Dataset.from_dict(train)\n",
    "valid = Dataset.from_dict(valid)\n",
    "test = Dataset.from_dict(test)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": train,\n",
    "    \"valid\": valid,\n",
    "    \"test\": test,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T20:16:07.253935Z",
     "iopub.status.busy": "2023-06-08T20:16:07.253403Z",
     "iopub.status.idle": "2023-06-08T20:16:09.300473Z",
     "shell.execute_reply": "2023-06-08T20:16:09.299223Z",
     "shell.execute_reply.started": "2023-06-08T20:16:07.253887Z"
    }
   },
   "outputs": [],
   "source": [
    "# src_lang and tgt_lang are only used by mBART. Otherwise, they are automatically ignored.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, src_lang=\"bn_IN\", tgt_lang=\"bn_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T20:16:13.120083Z",
     "iopub.status.busy": "2023-06-08T20:16:13.118830Z",
     "iopub.status.idle": "2023-06-08T20:16:16.106910Z",
     "shell.execute_reply": "2023-06-08T20:16:16.105756Z",
     "shell.execute_reply.started": "2023-06-08T20:16:13.120035Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    input_feature = tokenizer(data[\"question\"], truncation=True, max_length=MAX_INPUT_LENGTH)\n",
    "    label = tokenizer(data[\"summary\"], truncation=True, max_length=MAX_OUTPUT_LENGTH)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_feature[\"input_ids\"],\n",
    "        \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "        \"labels\": label[\"input_ids\"],\n",
    "    }\n",
    "\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize_data,\n",
    "    remove_columns=[\"summary\", \"question\"],\n",
    "    batched=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T10:54:51.934435Z",
     "iopub.status.busy": "2023-06-08T10:54:51.934020Z",
     "iopub.status.idle": "2023-06-08T10:55:05.683463Z",
     "shell.execute_reply": "2023-06-08T10:55:05.682427Z",
     "shell.execute_reply.started": "2023-06-08T10:54:51.934395Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL,\n",
    "    max_length=MAX_OUTPUT_LENGTH,\n",
    "    length_penalty=LENGTH_PENALTY,\n",
    "    no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE,\n",
    "    num_beams=NUM_BEAMS,\n",
    ")\n",
    "\n",
    "model = (AutoModelForSeq2SeqLM.from_pretrained(MODEL).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T10:55:05.685557Z",
     "iopub.status.busy": "2023-06-08T10:55:05.685163Z",
     "iopub.status.idle": "2023-06-08T10:55:05.691493Z",
     "shell.execute_reply": "2023-06-08T10:55:05.690212Z",
     "shell.execute_reply.started": "2023-06-08T10:55:05.685514Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T10:55:05.694368Z",
     "iopub.status.busy": "2023-06-08T10:55:05.693985Z",
     "iopub.status.idle": "2023-06-08T10:55:06.250383Z",
     "shell.execute_reply": "2023-06-08T10:55:06.249448Z",
     "shell.execute_reply.started": "2023-06-08T10:55:05.694332Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_score = evaluate.load(\"bertscore\")\n",
    "rouge = Rouge()\n",
    "\n",
    "def tokenize_sentence(arg):\n",
    "    encoded_arg = tokenizer(arg)\n",
    "    return tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "def metrics_func(eval_arg, return_bertscore = False):\n",
    "    preds, labels = eval_arg\n",
    "    \n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "    text_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    text_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    rouge_scores = rouge.get_scores(text_preds, text_labels, avg = True, ignore_empty = True)\n",
    "    results['rouge-1'] = rouge_scores['rouge-1']['f']\n",
    "    results['rouge-2'] = rouge_scores['rouge-2']['f']\n",
    "    results['rouge-l'] = rouge_scores['rouge-l']['f']\n",
    "    \n",
    "    if return_bertscore:\n",
    "        bertscore_result = bert_score.compute(\n",
    "            predictions=text_preds,\n",
    "            references=text_labels,\n",
    "            model_type=\"csebuetnlp/banglabert\",\n",
    "            num_layers=12,\n",
    "            batch_size=4\n",
    "        )\n",
    "        results['bertscore'] = mean([round(v, 4) for v in bertscore_result[\"f1\"]])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T10:55:06.255260Z",
     "iopub.status.busy": "2023-06-08T10:55:06.253800Z",
     "iopub.status.idle": "2023-06-08T10:55:06.261696Z",
     "shell.execute_reply": "2023-06-08T10:55:06.260659Z",
     "shell.execute_reply.started": "2023-06-08T10:55:06.255215Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T10:56:28.400034Z",
     "iopub.status.busy": "2023-06-08T10:56:28.398651Z",
     "iopub.status.idle": "2023-06-08T10:56:28.409790Z",
     "shell.execute_reply": "2023-06-08T10:56:28.408840Z",
     "shell.execute_reply.started": "2023-06-08T10:56:28.399974Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    report_to=\"wandb\" if USE_WANDB else \"none\",\n",
    "    output_dir = \"./results\",\n",
    "    overwrite_output_dir = True,\n",
    "    load_best_model_at_end = True,\n",
    "    log_level = \"error\",\n",
    "    num_train_epochs = EPOCHS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    warmup_steps = 0.2 * int(len(ds[\"train\"]) / BATCH_SIZE * EPOCHS),\n",
    "    optim = \"adamw_torch\",\n",
    "    weight_decay = WEIGHT_DECAY,\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    per_device_eval_batch_size = BATCH_SIZE,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    predict_with_generate = True,\n",
    "    generation_max_length = MAX_OUTPUT_LENGTH,\n",
    "    save_total_limit = 1,\n",
    "    logging_steps = 10,\n",
    "    push_to_hub = False,\n",
    "    group_by_length = True,\n",
    "    save_strategy=\"epoch\",\n",
    "    gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T10:57:44.100147Z",
     "iopub.status.busy": "2023-06-08T10:57:44.099108Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = metrics_func,\n",
    "    train_dataset = tokenized_ds[\"train\"],\n",
    "    eval_dataset = tokenized_ds[\"valid\"],\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir=\"./best_model/\")\n",
    "!rm -rf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
